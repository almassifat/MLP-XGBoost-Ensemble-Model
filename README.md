# ğŸš€ MLP + XGBoost Ensemble Model for Product Comparison

[![Python](https://img.shields.io/badge/Python-3.9-blue.svg)]()
[![PyTorch](https://img.shields.io/badge/Framework-PyTorch-orange.svg)]()
[![XGBoost](https://img.shields.io/badge/Model-XGBoost-green.svg)]()
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)]()

---

## ğŸ“ Overview

This project implements a **hybrid deep learning + gradient boosting ensemble model** to compare **two products** and determine which one is better.  
It leverages **BERT-based embeddings** for textual reviews, combines them with **tabular features**, and uses a **Multi-Layer Perceptron (MLP)** along with **XGBoost** to achieve **high interpretability and accuracy**.

---

## âœ¨ Features

- ğŸ§  **BERT-based review embeddings** (DistilBERT / BERT-base)  
- ğŸ”¢ **Tabular features:** CPU, GPU, RAM, SSD, Rating, Price  
- âš™ï¸ **MLP deep learning model** + **XGBoost ensemble**  
- ğŸ“ˆ **Performance visualizations** (confusion matrix, loss & accuracy curves)  
- ğŸ§® **Explainability:** Feature importance & SHAP values  

---

## ğŸ§¾ Project Pipeline

| Step | Description |
|------|-------------|
| 1ï¸âƒ£ | Data analysis, cleaning, normalization |
| 2ï¸âƒ£ | Feature engineering (difference-based numerical features) |
| 3ï¸âƒ£ | Text encoding using HuggingFace **BERT** |
| 4ï¸âƒ£ | Deep learning **MLP** model for numeric features |
| 5ï¸âƒ£ | **XGBoost** classifier for structured data |
| 6ï¸âƒ£ | Ensemble via **probability averaging** for final decision |
| âœ… | Evaluation using accuracy, precision, recall, F1, AUC, and visualization plots |

---

## ğŸ§  Model Highlights

- âœï¸ **Semantic understanding** of reviews using BERT  
- ğŸ¯ **Custom importance weighting** (CPU/GPU emphasized over display features)  
- ğŸ”— **Ensemble learning** improves performance over individual models  
- ğŸ“Š **Explainable AI:** Feature importance and SHAP analysis for decision reasoning  

---



## âš¡ Installation

```bash
git clone https://github.com/yourusername/MLP-XGBoost-Ensemble-Model.git
cd MLP-XGBoost-Ensemble-Model
pip install -r requirements.txt
